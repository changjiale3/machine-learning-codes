{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:start binaryzation_features()\n",
      "DEBUG:root:end binaryzation_features(), cost 0.32886695861816406 seconds\n",
      "DEBUG:root:start train()\n",
      "DEBUG:root:end train(), cost 96.76921653747559 seconds\n",
      "DEBUG:root:start predict()\n",
      "DEBUG:root:end predict(), cost 0.060164451599121094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruacy socre is  0.8598845598845599\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "total_class = 10\n",
    "\n",
    "def log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        logging.debug('start %s()' % func.__name__)\n",
    "        ret = func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.debug('end %s(), cost %s seconds' % (func.__name__,end_time-start_time))\n",
    "\n",
    "        return ret\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# 二值化\n",
    "def binaryzation(img):\n",
    "    cv_img = img.astype(np.uint8)\n",
    "    cv2.threshold(cv_img,50,1,cv2.THRESH_BINARY_INV,cv_img)\n",
    "    return cv_img\n",
    "\n",
    "@log\n",
    "def binaryzation_features(trainset):\n",
    "    features = []\n",
    "\n",
    "    for img in trainset:\n",
    "        img = np.reshape(img,(28,28))\n",
    "        cv_img = img.astype(np.uint8)\n",
    "\n",
    "        img_b = binaryzation(cv_img)\n",
    "        # hog_feature = np.transpose(hog_feature)\n",
    "        features.append(img_b)\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = np.reshape(features,(-1,784))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "class Tree(object):\n",
    "    def __init__(self,node_type,Class = None, feature = None):\n",
    "        self.node_type = node_type\n",
    "        self.dict = {}\n",
    "        self.Class = Class\n",
    "        self.feature = feature\n",
    "\n",
    "    def add_tree(self,val,tree):\n",
    "        self.dict[val] = tree\n",
    "\n",
    "    def predict(self,features):\n",
    "        if self.node_type == 'leaf':\n",
    "            return self.Class\n",
    "\n",
    "        tree = self.dict[features[self.feature]]\n",
    "        return tree.predict(features)\n",
    "\n",
    "def calc_ent(x):\n",
    "    \"\"\"\n",
    "        calculate shanno ent of x\n",
    "    \"\"\"\n",
    "\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    ent = 0.0\n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x == x_value].shape[0]) / x.shape[0]\n",
    "        logp = np.log2(p)\n",
    "        ent -= p * logp\n",
    "\n",
    "    return ent\n",
    "\n",
    "def calc_condition_ent(x, y):\n",
    "    \"\"\"\n",
    "        calculate ent H(y|x)\n",
    "    \"\"\"\n",
    "\n",
    "    # calc ent(y|x)\n",
    "    x_value_list = set([x[i] for i in range(x.shape[0])])\n",
    "    ent = 0.0\n",
    "    for x_value in x_value_list:\n",
    "        sub_y = y[x == x_value]\n",
    "        temp_ent = calc_ent(sub_y)\n",
    "        ent += (float(sub_y.shape[0]) / y.shape[0]) * temp_ent\n",
    "\n",
    "    return ent\n",
    "\n",
    "def calc_ent_grap(x,y):\n",
    "    \"\"\"\n",
    "        calculate ent grap\n",
    "    \"\"\"\n",
    "\n",
    "    base_ent = calc_ent(y)\n",
    "    condition_ent = calc_condition_ent(x, y)\n",
    "    ent_grap = base_ent - condition_ent\n",
    "\n",
    "    return ent_grap\n",
    "\n",
    "def recurse_train(train_set,train_label,features,epsilon):\n",
    "    global total_class\n",
    "\n",
    "    LEAF = 'leaf'\n",
    "    INTERNAL = 'internal'\n",
    "\n",
    "    # 步骤1——如果train_set中的所有实例都属于同一类Ck\n",
    "    label_set = set(train_label)\n",
    "    if len(label_set) == 1:\n",
    "        return Tree(LEAF,Class = label_set.pop())\n",
    "\n",
    "    # 步骤2——如果features为空\n",
    "    (max_class,max_len) = max([(i,len(list(filter(lambda x:x==i,train_label)))) for i in range(total_class)],key = lambda x:x[1])\n",
    "\n",
    "    if len(features) == 0:\n",
    "        return Tree(LEAF,Class = max_class)\n",
    "\n",
    "    # 步骤3——计算信息增益\n",
    "    max_feature = 0\n",
    "    max_gda = 0\n",
    "\n",
    "    D = train_label\n",
    "    HD = calc_ent(D)\n",
    "    for feature in features:\n",
    "        A = np.array(train_set[:,feature].flat)\n",
    "        gda = HD - calc_condition_ent(A,D)\n",
    "\n",
    "        if gda > max_gda:\n",
    "            max_gda,max_feature = gda,feature\n",
    "\n",
    "    # 步骤4——小于阈值\n",
    "    if max_gda < epsilon:\n",
    "        return Tree(LEAF,Class = max_class)\n",
    "\n",
    "    # 步骤5——构建非空子集\n",
    "    sub_features = list(filter(lambda x:x!=max_feature,features))\n",
    "    tree = Tree(INTERNAL,feature=max_feature)\n",
    "\n",
    "    feature_col = np.array(train_set[:,max_feature].flat)\n",
    "    feature_value_list = set([feature_col[i] for i in range(feature_col.shape[0])])\n",
    "    for feature_value in feature_value_list:\n",
    "\n",
    "        index = []\n",
    "        for i in range(len(train_label)):\n",
    "            if train_set[i][max_feature] == feature_value:\n",
    "                index.append(i)\n",
    "\n",
    "        sub_train_set = train_set[index]\n",
    "        sub_train_label = train_label[index]\n",
    "\n",
    "        sub_tree = recurse_train(sub_train_set,sub_train_label,sub_features,epsilon)\n",
    "        tree.add_tree(feature_value,sub_tree)\n",
    "\n",
    "    return tree\n",
    "\n",
    "@log\n",
    "def train(train_set,train_label,features,epsilon):\n",
    "    return recurse_train(train_set,train_label,features,epsilon)\n",
    "\n",
    "@log\n",
    "def predict(test_set,tree):\n",
    "\n",
    "    result = []\n",
    "    for features in test_set:\n",
    "        tmp_predict = tree.predict(features)\n",
    "        result.append(tmp_predict)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    raw_data = pd.read_csv('../data/train.csv',header=0)\n",
    "    data = raw_data.values\n",
    "\n",
    "    imgs = data[0::,1::]\n",
    "    labels = data[::,0]\n",
    "\n",
    "    # 图片二值化\n",
    "    features = binaryzation_features(imgs)\n",
    "\n",
    "    # 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=23323)\n",
    "\n",
    "    tree = train(train_features,train_labels,[i for i in range(784)],0.1)\n",
    "    test_predict = predict(test_features,tree)\n",
    "    score = accuracy_score(test_labels,test_predict)\n",
    "\n",
    "    print(\"The accruacy socre is \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
