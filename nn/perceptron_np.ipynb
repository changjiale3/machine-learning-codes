{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Reference: [blog](https://blog.csdn.net/wds2006sdo/article/details/51923546) + [github](https://github.com/WenDesi/lihang_book_algorithm/blob/master/perceptron/binary_perceptron.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orris/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Prepare data.\n",
    "\n",
    "准备MNIST数据集,原来label为0的新label也是0,原来label>0的就设置为1.\n",
    "\n",
    "这里直接已经处理好的数据集`train_binary.csv`,下载地址参考引用链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../data/train_binary.csv', header=0)\n",
    "data = raw_data.values\n",
    "imgs = data[0:, 1:] # for one row, the first column is the label followed by the image data\n",
    "labels = data[:, 0]\n",
    "\n",
    "# normalize\n",
    "imgs = imgs / 255\n",
    "\n",
    "# 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, random_state=23323)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Build model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, num_weights):\n",
    "        self.learning_rate = 1e-5\n",
    "        self.weights = np.zeros(num_weights)\n",
    "        self.bias = 0.0\n",
    "        self.num_epochs = 5000 # number of updates\n",
    "        self.log_every = 500\n",
    "    \n",
    "    def fit(self, features, labels):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            choice = np.random.randint(len(features))\n",
    "            feature = features[choice]\n",
    "            label = labels[choice] # label in {0, 1}\n",
    "            label = 2 * label - 1 # label in {-1, 1}\n",
    "            y_predicted = np.sum(self.weights * feature) + self.bias\n",
    "            loss = - label * y_predicted\n",
    "            \n",
    "            if epoch % self.log_every == 0:\n",
    "                print('epoch {}: loss={}'.format(epoch, loss))\n",
    " \n",
    "        \n",
    "            # SGD optimization\n",
    "            dws = - label * feature\n",
    "            db = - label\n",
    "\n",
    "            if loss < 0: # update only if 'y(wx + b) <= 0'\n",
    "                continue\n",
    "            self.weights -= self.learning_rate * dws\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "   \n",
    "    def predict(self, features, labels):\n",
    "        features = np.asarray(features)\n",
    "        tmp = np.matmul(features, self.weights)\n",
    "        y_predicted = np.matmul(features, self.weights) + self.bias\n",
    "        for index, y_pred in enumerate(y_predicted):\n",
    "            y_predicted[index] = int(y_pred > 0)\n",
    "        \n",
    "        print('accuracy rate:', np.sum(y_predicted == labels) / len(y_predicted))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Train model and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss=-0.0\n",
      "epoch 500: loss=-0.001399946482122261\n",
      "epoch 1000: loss=-0.0005619598615916957\n",
      "epoch 1500: loss=-0.0008822725105728567\n",
      "epoch 2000: loss=-0.0009164312187620147\n",
      "epoch 2500: loss=-0.0015194402153018071\n",
      "epoch 3000: loss=-0.0009407166474432911\n",
      "epoch 3500: loss=-0.0015548101499423296\n",
      "epoch 4000: loss=-0.001284720953479431\n",
      "epoch 4500: loss=-0.0013120521337946945\n",
      "accuracy rate: 0.9627705627705627\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "num_weights = len(x_train[0])\n",
    "p = Perceptron(num_weights=num_weights)\n",
    "p.fit(x_train, y_train)\n",
    "y_predicted = p.predict(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
