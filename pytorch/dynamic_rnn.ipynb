{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamic_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def dynamic_rnn(cell, inputs, sequence_length):\n",
    "    '''\n",
    "        Inputs:\n",
    "            cell: torch.nn.LSTMCell instance\n",
    "            inputs: (batch_size, max_timestep, input_size)\n",
    "            sequence_length: (batch_size,)\n",
    "        Outputs:\n",
    "            outputs: (batch_size, max_timestep, hidden_size)\n",
    "            final_states(NOT SUPPORT): a tuple of (hidden_state, cell_state) which are the final states of the cell\n",
    "    '''\n",
    "    def sort_batch(data, lengths):\n",
    "        '''\n",
    "            data: (batch_size, ?)\n",
    "            lengths: (batch_size,)\n",
    "        '''\n",
    "        sorted_indices, sorted_lengths = zip(*sorted(enumerate(lengths), key=lambda x: x[1], reverse=True))\n",
    "        sorted_indices = list(sorted_indices)\n",
    "        sorted_data = data[sorted_indices]\n",
    "        return sorted_data, sorted_lengths, sorted_indices\n",
    "\n",
    "    dtype = inputs.dtype\n",
    "    device = inputs.device\n",
    "        \n",
    "    sorted_inputs, sorted_lengths, sorted_indices = sort_batch(inputs, sequence_length)\n",
    "    \n",
    "    decoder_lengths = [length - 1 for length in sorted_lengths]\n",
    "\n",
    "    sorted_outputs = torch.zeros((inputs.shape[0], inputs.shape[1], cell.hidden_size), dtype=dtype).to(device)\n",
    "    outputs = torch.zeros((inputs.shape[0], inputs.shape[1], cell.hidden_size), dtype=dtype).to(device)\n",
    "\n",
    "\n",
    "    h, c = None, None\n",
    "    for step in range(sorted_lengths[0]):\n",
    "        curr_batch_size = sum([l > step for l in sorted_lengths])\n",
    "        #sorted_inputs = sorted_inputs[:curr_batch_size, step, :] # (curr_batch_size, timesteps, input_size)\n",
    "        curr_inputs = sorted_inputs[:curr_batch_size, step, :] # (batch_size, input_size)\n",
    "\n",
    "        if h is None or c is None:\n",
    "            h, c = cell(curr_inputs, None) # (curr_batch_size, hidden_size)\n",
    "        else:\n",
    "            h, c = h[:curr_batch_size], c[:curr_batch_size] # (curr_batch_size, hidden_size)\n",
    "            h, c = cell(curr_inputs, (h, c)) # (curr_batch_size, hidden_size)\n",
    "\n",
    "        sorted_outputs[:curr_batch_size, step, :] = h\n",
    "\n",
    "    # sort back\n",
    "    outputs[sorted_indices] = sorted_outputs\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. fixed-lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the inputs are fixed-lengths data, we recommend to use `torch.nn.LSTM` rather than `torch.nn.LSTMCell` and `dynamic_rnn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable-lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 5, 2])\n",
      "tensor([[[-0.5350, -0.0709],\n",
      "         [-0.4732, -0.1139],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.9036, -0.5725],\n",
      "         [-0.8133,  0.2226],\n",
      "         [-0.0077,  1.3141],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.4904, -1.1200],\n",
      "         [-0.1805, -0.1135],\n",
      "         [-1.2188,  1.8980],\n",
      "         [ 0.5987,  0.8136],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.0816, -1.6631],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]])\n",
      "------------------------------\n",
      "sequence_length:\n",
      "tensor([2, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(4, 5, 2)\n",
    "sequence_length = torch.LongTensor([2, 3, 4, 1])\n",
    "\n",
    "for i in range(inputs.shape[0]):\n",
    "    inputs[i, sequence_length[i]:, :] = 0\n",
    "    \n",
    "lstm = torch.nn.LSTMCell(input_size=2, hidden_size=4)\n",
    "\n",
    "print('inputs:')\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "\n",
    "print('-'*30)\n",
    "print('sequence_length:')\n",
    "print(sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 4])\n",
      "tensor([[[-0.0603,  0.1638,  0.0383, -0.2045],\n",
      "         [-0.1093,  0.2398,  0.0594, -0.2780],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1622,  0.0282,  0.1451, -0.0276],\n",
      "         [-0.1598,  0.1900,  0.0993, -0.2576],\n",
      "         [-0.2170,  0.1980,  0.2763, -0.1226],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0436,  0.2228, -0.0259, -0.3050],\n",
      "         [-0.0582,  0.2379,  0.0424, -0.2694],\n",
      "         [-0.0855,  0.3073,  0.1373, -0.3327],\n",
      "         [-0.1962,  0.2263,  0.3077, -0.1008],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0332,  0.1801, -0.0299, -0.2301],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<PutBackward>)\n"
     ]
    }
   ],
   "source": [
    "outputs = dynamic_rnn(lstm, inputs, sequence_length=sequence_length)\n",
    "\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "tensor([[[-0.0603,  0.1638,  0.0383, -0.2045],\n",
      "         [-0.1093,  0.2398,  0.0594, -0.2780]]], grad_fn=<CopySlices>)\n",
      "torch.Size([1, 3, 2])\n",
      "tensor([[[-0.1622,  0.0282,  0.1451, -0.0276],\n",
      "         [-0.1598,  0.1900,  0.0993, -0.2576],\n",
      "         [-0.2170,  0.1980,  0.2763, -0.1226]]], grad_fn=<CopySlices>)\n",
      "torch.Size([1, 4, 2])\n",
      "tensor([[[ 0.0436,  0.2228, -0.0259, -0.3050],\n",
      "         [-0.0582,  0.2379,  0.0424, -0.2694],\n",
      "         [-0.0855,  0.3073,  0.1373, -0.3327],\n",
      "         [-0.1962,  0.2263,  0.3077, -0.1008]]], grad_fn=<CopySlices>)\n",
      "torch.Size([1, 1, 2])\n",
      "tensor([[[ 0.0332,  0.1801, -0.0299, -0.2301]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(inputs.shape[0]):\n",
    "    curr_inputs = inputs[i, :sequence_length[i], :].unsqueeze(0)\n",
    "    outputs = torch.zeros((1, sequence_length[i], lstm.hidden_size), dtype=torch.float)\n",
    "    print(curr_inputs.shape)\n",
    "    h, c = None, None\n",
    "    for step in range(sequence_length[i]):\n",
    "        if h is None or c is None:\n",
    "            h, c = lstm(curr_inputs[:, step, :], None)\n",
    "        else:\n",
    "            h, c = lstm(curr_inputs[:, step, :], (h, c))\n",
    "        outputs[:, step, :] = h\n",
    "        \n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
