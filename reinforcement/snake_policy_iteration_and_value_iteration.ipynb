{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from snake import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Define policy iteration class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIteration(object):\n",
    "    @staticmethod\n",
    "    def _policy_evaluation(agent, max_iter=-1):\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            new_value_s = agent.value_s.copy() # (state_size)\n",
    "            for s in range(1, agent.state_size): # 0 is invalid, because SnakeEnv defines observation_space to be 101\n",
    "                a = agent.pi[s]\n",
    "                new_value_s[s] = np.matmul(agent.p[a, s, :], agent.r + agent.gamma * agent.value_s) # (state_size)\n",
    "            diff = np.sqrt(np.sum((new_value_s - agent.value_s) ** 2))\n",
    "\n",
    "            if diff < 1e-6:\n",
    "                break\n",
    "            else:\n",
    "                agent.value_s = new_value_s\n",
    "                \n",
    "            iteration += 1\n",
    "            if iteration == max_iter:\n",
    "                break\n",
    "\n",
    "    @staticmethod\n",
    "    def _policy_improvement(agent):\n",
    "        new_policy = np.zeros_like(agent.pi) # (action_size, state_size, state_size)\n",
    "        for s in range(1, agent.state_size):\n",
    "            for a in range(agent.action_size): # iterate a !!! not a = agent.pi[s], but iteration!!!!\n",
    "                # update action-value function\n",
    "                agent.value_sa[s, a] = np.dot(agent.p[a, s, :], agent.r + agent.gamma * agent.value_s)\n",
    "            new_policy[s] = np.argmax(agent.value_sa[s, :]) # select the max action !!! not [s, a], but [s, :]\n",
    "        if np.all(np.equal(new_policy, agent.pi)):\n",
    "            return True # converge\n",
    "        else:\n",
    "            agent.pi = new_policy\n",
    "            return False # not converge\n",
    "\n",
    "    @staticmethod\n",
    "    def policy_iteration(agent, max_iter=-1): # max_iter is corresponding to policy evaluation\n",
    "        while True:\n",
    "            PolicyIteration._policy_evaluation(agent, max_iter)\n",
    "            ret = PolicyIteration._policy_improvement(agent)\n",
    "            if ret:\n",
    "                break\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def policy_iteration_time(agent, max_iter=-1):\n",
    "        while True:\n",
    "            with timer('Timer PolicyEval'):\n",
    "                PolicyIteration._policy_evaluation(agent, max_iter)\n",
    "            with timer('Timer PolicyImprove'):\n",
    "                ret = PolicyIteration._policy_improvement(agent)\n",
    "            if ret:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No ladders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ladders\n",
      "return: 66\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('No ladders')\n",
    "env = SnakeEnv(0, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "PolicyIteration.policy_iteration(agent)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random ladders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random ladders\n",
      "return: 87\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "return: -47\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "return: 93\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "return: 75\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Random ladders')\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "\n",
    "# 1. all 1\n",
    "agent.pi[:] = 1\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)\n",
    "\n",
    "# 2. all 0\n",
    "agent.pi[:] = 0\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)\n",
    "\n",
    "\n",
    "# 3. [1] * 97 + [] * 3\n",
    "agent.pi[:-3] = 1\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)\n",
    "\n",
    "\n",
    "# 4. Policy Iteration\n",
    "PolicyIteration.policy_iteration(agent)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the time policy evaluation and policy improvement runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer PolicyEval COST:0.10278606414794922\n",
      "Timer PolicyImprove COST:0.0025739669799804688\n",
      "Timer PolicyEval COST:0.07129621505737305\n",
      "Timer PolicyImprove COST:0.0029616355895996094\n",
      "Timer PolicyEval COST:0.05581331253051758\n",
      "Timer PolicyImprove COST:0.002955913543701172\n",
      "Timer PolicyEval COST:0.03937983512878418\n",
      "Timer PolicyImprove COST:0.0026044845581054688\n",
      "return: 88\n",
      "[0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "PolicyIteration.policy_iteration_time(agent)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above the results, policy evaluation takes more time than policy improvement. What if we reduce the time spent on policy evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1: max_iter=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer PolicyEval COST:0.05925488471984863\n",
      "Timer PolicyImprove COST:0.0026290416717529297\n",
      "Timer PolicyEval COST:0.05691027641296387\n",
      "Timer PolicyImprove COST:0.002716064453125\n",
      "Timer PolicyEval COST:0.054637908935546875\n",
      "Timer PolicyImprove COST:0.0029664039611816406\n",
      "Timer PolicyEval COST:0.046237945556640625\n",
      "Timer PolicyImprove COST:0.003295421600341797\n",
      "return: 88\n",
      "[0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "PolicyIteration.policy_iteration_time(agent, max_iter=50)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2: max_iter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer PolicyEval COST:0.012920618057250977\n",
      "Timer PolicyImprove COST:0.003330230712890625\n",
      "Timer PolicyEval COST:0.012677669525146484\n",
      "Timer PolicyImprove COST:0.0027811527252197266\n",
      "Timer PolicyEval COST:0.01230621337890625\n",
      "Timer PolicyImprove COST:0.002826690673828125\n",
      "Timer PolicyEval COST:0.013787984848022461\n",
      "Timer PolicyImprove COST:0.0028400421142578125\n",
      "return: 88\n",
      "[0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "PolicyIteration.policy_iteration_time(agent, max_iter=10)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3: max_iter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer PolicyEval COST:0.0012767314910888672\n",
      "Timer PolicyImprove COST:0.002900838851928711\n",
      "Timer PolicyEval COST:0.0013184547424316406\n",
      "Timer PolicyImprove COST:0.0024771690368652344\n",
      "Timer PolicyEval COST:0.0016360282897949219\n",
      "Timer PolicyImprove COST:0.003149271011352539\n",
      "Timer PolicyEval COST:0.0012812614440917969\n",
      "Timer PolicyImprove COST:0.0030074119567871094\n",
      "Timer PolicyEval COST:0.0014488697052001953\n",
      "Timer PolicyImprove COST:0.002941608428955078\n",
      "Timer PolicyEval COST:0.0012707710266113281\n",
      "Timer PolicyImprove COST:0.002722501754760742\n",
      "Timer PolicyEval COST:0.0011792182922363281\n",
      "Timer PolicyImprove COST:0.0026738643646240234\n",
      "return: 88\n",
      "[0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "PolicyIteration.policy_iteration_time(agent, max_iter=1)\n",
    "print('return:', eval_game(env, agent))\n",
    "print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results are the same, indicating the times of policy evaluation does not affect the final result. In fact, The program spends more time in iterating both policy evaluation and policy improvement. Since the time spent on policy improvement is less than policy evaluation, it saves time to reduce the iterations of policy evaluation. It is called **Value Iteration**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation for Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Value Iteration:<br\\>\n",
    "$v(s) \\leftarrow max_a{q(s, a)}$<br\\>\n",
    "$v(s) \\leftarrow max_a{\\sum_{s^{\\prime}}{p(s^{\\prime}|s, a)[r(s, a, s^{\\prime}) + \\gamma \\tilde{v}(s^{\\prime})]}}$\n",
    "\n",
    "2. Policy Improvement:<br/>\n",
    "$q(s_t, a_t) = \\sum_{s_{t+1}}{      p(s_{t+1}|s_t, a_t)[ r_{t+1} + \\gamma v_{\\pi}(s_{t+1})  ]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIFFERENCES:\n",
    "1. Number of iterations for policy evalution;\n",
    "2. Ways of updating state-value function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration(object):\n",
    "    @staticmethod\n",
    "    def value_iteration(agent, max_iter=-1):\n",
    "        # update state-value function\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            new_value_s = np.zeros_like(agent.value_s)\n",
    "            for s in range(1, agent.state_size): # 1 is important !!!\n",
    "                value_sas = list()\n",
    "                for a in range(agent.action_size):\n",
    "                    value_sa = np.dot(agent.p[a, s, :], agent.r + agent.gamma * agent.value_s)\n",
    "                    value_sas.append(value_sa)\n",
    "                new_value_s[s] = max(value_sas) # int or float???\n",
    "            diff = np.sqrt(np.sum((agent.value_s - new_value_s) ** 2))\n",
    "            if diff < 1e-6 or iteration == max_iter:\n",
    "                break\n",
    "            else:\n",
    "                agent.value_s = new_value_s # update agent's state-value function !!!\n",
    "        # update action-value function\n",
    "        for s in range(1, agent.state_size): # 1 is important !!!\n",
    "            for a in range(agent.action_size):\n",
    "                agent.value_sa[s, a] = np.dot(agent.p[a, s, :], agent.r + agent.gamma * agent.value_s)\n",
    "            agent.pi[s] = np.argmax(agent.value_sa[s, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration\n",
      "return: 92\n",
      "[0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "ValueIteration COST:0.24405908584594727\n",
      "\n",
      "Policy Iteration 10 iter\n",
      "return: 92\n",
      "[0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "PolicyIteration 10 iter COST:0.0500035285949707\n",
      "\n",
      "Policy Iteration 1 iter\n",
      "return: 92\n",
      "[0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "PolicyIteration 1 iter COST:0.024219989776611328\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "\n",
    "print('Value Iteration')\n",
    "with timer('ValueIteration'):\n",
    "    ValueIteration.value_iteration(agent)\n",
    "    print('return:', eval_game(env, agent))\n",
    "    print(agent.pi)\n",
    "\n",
    "print()\n",
    "np.random.seed(0)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "print('Policy Iteration 10 iter')\n",
    "with timer('PolicyIteration 10 iter'):\n",
    "    PolicyIteration.policy_iteration(agent, max_iter=10)\n",
    "    print('return:', eval_game(env, agent))\n",
    "    print(agent.pi)\n",
    "    \n",
    "print()\n",
    "np.random.seed(0)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "print('Policy Iteration 1 iter')\n",
    "with timer('PolicyIteration 1 iter'):\n",
    "    PolicyIteration.policy_iteration(agent, max_iter=1)\n",
    "    print('return:', eval_game(env, agent))\n",
    "    print(agent.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralizedPolicyIteration(object):\n",
    "    @staticmethod\n",
    "    def generalized_policy_iteration(agent):\n",
    "        ValueIteration.value_iteration(agent, 10)\n",
    "        PolicyIteration.policy_iteration(agent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration\n",
      "return: 92\n",
      "[0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "ValueIteration COST:0.029242277145385742\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "env = SnakeEnv(10, [3, 6])\n",
    "agent = TableAgent(0, env)\n",
    "\n",
    "print('Value Iteration')\n",
    "with timer('ValueIteration'):\n",
    "    GeneralizedPolicyIteration.generalized_policy_iteration(agent)\n",
    "    print('return:', eval_game(env, agent))\n",
    "    print(agent.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
