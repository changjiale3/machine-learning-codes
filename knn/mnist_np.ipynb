{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orris/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features(trainset):\n",
    "    features = []\n",
    "\n",
    "    hog = cv2.HOGDescriptor('../data/hog.xml')\n",
    "\n",
    "    for img in trainset:\n",
    "        img = np.reshape(img,(28,28))\n",
    "        cv_img = img.astype(np.uint8)\n",
    "\n",
    "        hog_feature = hog.compute(cv_img)\n",
    "        # hog_feature = np.transpose(hog_feature)\n",
    "        features.append(hog_feature)\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = np.reshape(features,(-1,324))\n",
    "\n",
    "    return features\n",
    "\n",
    "print('Start read data')\n",
    "\n",
    "time_1 = time.time()\n",
    "\n",
    "raw_data = pd.read_csv('../data/train.csv',header=0)\n",
    "data = raw_data.values\n",
    "\n",
    "imgs = data[0::,1::]\n",
    "labels = data[::,0]\n",
    "\n",
    "features = get_hog_features(imgs)\n",
    "\n",
    "# 选取 2/3 数据作为训练集， 1/3 数据作为测试集\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=23323)\n",
    "# print train_features.shape\n",
    "# print train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "# 利用opencv获取图像hog特征\n",
    "\n",
    "\n",
    "def Predict(testset,trainset,train_labels):\n",
    "    predict = []\n",
    "    count = 0\n",
    "\n",
    "    for test_vec in testset:\n",
    "        # 输出当前运行的测试用例坐标，用于测试\n",
    "        #print(count)\n",
    "        count += 1\n",
    "\n",
    "        knn_list = []       # 当前k个最近邻居\n",
    "        max_index = -1      # 当前k个最近邻居中距离最远点的坐标\n",
    "        max_dist = 0        # 当前k个最近邻居中距离最远点的距离\n",
    "\n",
    "        # 先将前k个点放入k个最近邻居中，填充满knn_list\n",
    "        for i in range(k):\n",
    "            label = train_labels[i]\n",
    "            train_vec = trainset[i]\n",
    "\n",
    "            dist = np.linalg.norm(train_vec - test_vec)         # 计算两个点的欧氏距离\n",
    "\n",
    "            knn_list.append((dist,label))\n",
    "\n",
    "        # 剩下的点\n",
    "        for i in range(k,len(train_labels)):\n",
    "            label = train_labels[i]\n",
    "            train_vec = trainset[i]\n",
    "\n",
    "            dist = np.linalg.norm(train_vec - test_vec)         # 计算两个点的欧氏距离\n",
    "\n",
    "            # 寻找10个邻近点钟距离最远的点\n",
    "            if max_index < 0:\n",
    "                for j in range(k):\n",
    "                    if max_dist < knn_list[j][0]:\n",
    "                        max_index = j\n",
    "                        max_dist = knn_list[max_index][0]\n",
    "\n",
    "            # 如果当前k个最近邻居中存在点距离比当前点距离远，则替换\n",
    "            if dist < max_dist:\n",
    "                knn_list[max_index] = (dist,label)\n",
    "                max_index = -1\n",
    "                max_dist = 0\n",
    "\n",
    "\n",
    "        # 统计选票\n",
    "        class_total = 10\n",
    "        class_count = [0 for i in range(class_total)]\n",
    "        for dist,label in knn_list:\n",
    "            class_count[label] += 1\n",
    "\n",
    "        # 找出最大选票\n",
    "        mmax = max(class_count)\n",
    "\n",
    "        # 找出最大选票标签\n",
    "        for i in range(class_total):\n",
    "            if mmax == class_count[i]:\n",
    "                predict.append(i)\n",
    "                break\n",
    "\n",
    "    return np.array(predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "time_2 = time.time()\n",
    "print('read data cost ',time_2 - time_1,' second','\\n')\n",
    "\n",
    "print('Start training')\n",
    "print('knn do not need to train')\n",
    "time_3 = time.time()\n",
    "print('training cost ',time_3 - time_2,' second','\\n')\n",
    "\n",
    "print('Start predicting')\n",
    "test_predict = Predict(test_features,train_features,train_labels)\n",
    "time_4 = time.time()\n",
    "print('predicting cost ',time_4 - time_3,' second','\\n')\n",
    "\n",
    "score = accuracy_score(test_labels,test_predict)\n",
    "print(\"The accruacy socre is \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
